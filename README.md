<table>
  <tr>
    <td align="center">
      <img src="detect_preference_gpt4_updated.png" alt="Preference Alignment" width="700"><br>
      <strong>Preference Alignment</strong>
    </td>
    <td align="center">
      <img src="detect_hateful_gpt4_updated.png" alt="Hatefulness" width="700"><br>
      <strong>Hatefulness</strong>
    </td>
  </tr>
  <tr>
    <td align="center">
      <img src="detect_offensive_gpt4_updated.png" alt="Offensiveness" width="700"><br>
      <strong>Offensiveness</strong>
    </td>
    <td align="center">
      <img src="detect_toxic_gpt4_updated.png" alt="Toxicity" width="700"><br>
      <strong>Toxicity</strong>
    </td>
  </tr>
</table>

<p align="center"><em>(Updated Figure 3 & 6) The AUC of different methods for four datasets with LLM cheaters using GPT-4 to generate labels. FaitCrowd and AggNet are the two suggested baselines. AggNet only works for binary labels which does not directly apply to the preference alignment dataset.</em></p>
